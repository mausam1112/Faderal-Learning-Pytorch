{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)\n",
    "        self.fc1 = nn.Linear(2048, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "\n",
    "\n",
    "def client_update(client_model, optimizer, train_loader, epoch=5):\n",
    "    model.train()\n",
    "    for e in range(epoch):\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            output = client_model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "def server_aggregate(global_model, client_models):\n",
    "    global_dict = global_model.state_dict()\n",
    "    for k in global_dict.keys():\n",
    "        global_dict[k] = torch.stack([client_models[i].state_dict()[k] for i in range(len(client_models))], 0).mean(0)\n",
    "    global_model.load_state_dict(global_dict)\n",
    "    for model in client_models:\n",
    "        model.load_state_dict(global_model.state_dict())\n",
    "\n",
    "def test(global_model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            output = global_model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    acc = correct / len(test_loader.dataset)\n",
    "\n",
    "    return test_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-th round\n",
      "average train loss 0.725 | test loss 0.469 | test acc: 0.864\n",
      "1-th round\n",
      "average train loss 0.234 | test loss 0.242 | test acc: 0.927\n",
      "2-th round\n",
      "average train loss 0.143 | test loss 0.197 | test acc: 0.944\n",
      "3-th round\n",
      "average train loss 0.0341 | test loss 0.165 | test acc: 0.952\n",
      "4-th round\n",
      "average train loss 0.0212 | test loss 0.142 | test acc: 0.959\n"
     ]
    }
   ],
   "source": [
    "# IID case: all the clients have images of all the classes\n",
    "\n",
    "# Hyperparameters\n",
    "\n",
    "num_clients = 100\n",
    "num_selected = 10\n",
    "num_rounds = 5\n",
    "epochs = 5\n",
    "batch_size = 32\n",
    "\n",
    "# Creating decentralized datasets\n",
    "\n",
    "traindata = datasets.MNIST('./data', train=True, download=True,\n",
    "                       transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))])\n",
    "                       )\n",
    "traindata_split = torch.utils.data.random_split(traindata, [int(traindata.data.shape[0] / num_clients) for _ in range(num_clients)])\n",
    "train_loader = [torch.utils.data.DataLoader(x, batch_size=batch_size, shuffle=True) for x in traindata_split]\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('./data', train=False, transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))])\n",
    "        ), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Instantiate models and optimizers\n",
    "\n",
    "global_model = Net().cuda()\n",
    "client_models = [Net().cuda() for _ in range(num_selected)]\n",
    "for model in client_models:\n",
    "    model.load_state_dict(global_model.state_dict())\n",
    "\n",
    "opt = [optim.SGD(model.parameters(), lr=0.1) for model in client_models]\n",
    "\n",
    "# Runnining FL\n",
    "\n",
    "for r in range(num_rounds):\n",
    "    # select random clients\n",
    "    client_idx = np.random.permutation(num_clients)[:num_selected]\n",
    "\n",
    "    # client update\n",
    "    loss = 0\n",
    "    for i in range(num_selected):\n",
    "        loss += client_update(client_models[i], opt[i], train_loader[client_idx[i]], epoch=epochs)\n",
    "    \n",
    "    # serer aggregate\n",
    "    server_aggregate(global_model, client_models)\n",
    "    test_loss, acc = test(global_model, test_loader)\n",
    "    \n",
    "    print('%d-th round' % r)\n",
    "    print('average train loss %0.3g | test loss %0.3g | test acc: %0.3f' % (loss / num_selected, test_loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-th round\n",
      "average train loss 0.0252 | test loss 2.64 | test acc: 0.306\n",
      "1-th round\n",
      "average train loss 0.0479 | test loss 2.09 | test acc: 0.202\n",
      "2-th round\n",
      "average train loss 0.0222 | test loss 2.06 | test acc: 0.271\n",
      "3-th round\n",
      "average train loss 0.00894 | test loss 2.6 | test acc: 0.357\n",
      "4-th round\n",
      "average train loss 0.00286 | test loss 2.6 | test acc: 0.213\n",
      "5-th round\n",
      "average train loss 0.00146 | test loss 2.05 | test acc: 0.365\n",
      "6-th round\n",
      "average train loss 0.0056 | test loss 1.75 | test acc: 0.486\n",
      "7-th round\n",
      "average train loss 0.00206 | test loss 1.53 | test acc: 0.616\n",
      "8-th round\n",
      "average train loss 0.00691 | test loss 1.71 | test acc: 0.580\n",
      "9-th round\n",
      "average train loss 0.00242 | test loss 1.94 | test acc: 0.570\n",
      "10-th round\n",
      "average train loss 0.000962 | test loss 1.77 | test acc: 0.541\n",
      "11-th round\n",
      "average train loss 0.00369 | test loss 1.84 | test acc: 0.596\n",
      "12-th round\n",
      "average train loss 0.00442 | test loss 1.15 | test acc: 0.650\n",
      "13-th round\n",
      "average train loss 0.00333 | test loss 1.07 | test acc: 0.657\n",
      "14-th round\n",
      "average train loss 0.00228 | test loss 1.04 | test acc: 0.622\n",
      "15-th round\n",
      "average train loss 0.000592 | test loss 0.987 | test acc: 0.671\n",
      "16-th round\n",
      "average train loss 0.0083 | test loss 0.517 | test acc: 0.817\n",
      "17-th round\n",
      "average train loss 0.000318 | test loss 0.65 | test acc: 0.769\n",
      "18-th round\n",
      "average train loss 0.00283 | test loss 0.735 | test acc: 0.727\n",
      "19-th round\n",
      "average train loss 0.00254 | test loss 1.95 | test acc: 0.448\n",
      "20-th round\n",
      "average train loss 0.00406 | test loss 0.759 | test acc: 0.710\n",
      "21-th round\n",
      "average train loss 0.00178 | test loss 0.814 | test acc: 0.714\n",
      "22-th round\n",
      "average train loss 0.0163 | test loss 0.615 | test acc: 0.779\n",
      "23-th round\n",
      "average train loss 0.000519 | test loss 0.722 | test acc: 0.771\n",
      "24-th round\n",
      "average train loss 0.000414 | test loss 0.699 | test acc: 0.727\n",
      "25-th round\n",
      "average train loss 0.000648 | test loss 0.668 | test acc: 0.757\n",
      "26-th round\n",
      "average train loss 0.000255 | test loss 0.63 | test acc: 0.784\n",
      "27-th round\n",
      "average train loss 0.00142 | test loss 0.487 | test acc: 0.843\n",
      "28-th round\n",
      "average train loss 0.000431 | test loss 0.372 | test acc: 0.868\n",
      "29-th round\n",
      "average train loss 0.00184 | test loss 1.4 | test acc: 0.642\n",
      "30-th round\n",
      "average train loss 0.000514 | test loss 0.536 | test acc: 0.798\n",
      "31-th round\n",
      "average train loss 0.000893 | test loss 0.689 | test acc: 0.765\n",
      "32-th round\n",
      "average train loss 0.00131 | test loss 0.771 | test acc: 0.746\n",
      "33-th round\n",
      "average train loss 0.000432 | test loss 0.846 | test acc: 0.722\n",
      "34-th round\n",
      "average train loss 0.000256 | test loss 0.963 | test acc: 0.717\n",
      "35-th round\n",
      "average train loss 0.00171 | test loss 0.41 | test acc: 0.869\n",
      "36-th round\n",
      "average train loss 0.000613 | test loss 0.208 | test acc: 0.933\n",
      "37-th round\n",
      "average train loss 0.000445 | test loss 0.26 | test acc: 0.917\n",
      "38-th round\n",
      "average train loss 0.000419 | test loss 0.354 | test acc: 0.883\n",
      "39-th round\n",
      "average train loss 0.000576 | test loss 0.241 | test acc: 0.922\n",
      "40-th round\n",
      "average train loss 0.000157 | test loss 0.65 | test acc: 0.786\n",
      "41-th round\n",
      "average train loss 5.25e-05 | test loss 0.303 | test acc: 0.905\n",
      "42-th round\n",
      "average train loss 0.00022 | test loss 0.468 | test acc: 0.841\n",
      "43-th round\n",
      "average train loss 0.000505 | test loss 0.626 | test acc: 0.801\n",
      "44-th round\n",
      "average train loss 0.000667 | test loss 0.225 | test acc: 0.929\n",
      "45-th round\n",
      "average train loss 0.00153 | test loss 0.33 | test acc: 0.897\n",
      "46-th round\n",
      "average train loss 0.0011 | test loss 0.211 | test acc: 0.938\n",
      "47-th round\n",
      "average train loss 0.000963 | test loss 0.237 | test acc: 0.916\n",
      "48-th round\n",
      "average train loss 0.000113 | test loss 0.238 | test acc: 0.919\n",
      "49-th round\n",
      "average train loss 0.000441 | test loss 0.52 | test acc: 0.840\n"
     ]
    }
   ],
   "source": [
    "# NON-IID case: every client has images of two categories chosen from [0, 1], [2, 3], [4, 5], [6, 7], or [8, 9].\n",
    "\n",
    "# Hyperparameters\n",
    "\n",
    "num_clients = 100\n",
    "num_selected = 5\n",
    "num_rounds = 50\n",
    "epochs = 5\n",
    "batch_size = 32\n",
    "\n",
    "# Creating decentralized datasets\n",
    "\n",
    "traindata = datasets.MNIST('./data', train=True, download=True,\n",
    "                       transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))])\n",
    "                       )\n",
    "target_labels = torch.stack([traindata.targets == i for i in range(10)])\n",
    "target_labels_split = []\n",
    "for i in range(5):\n",
    "    target_labels_split += torch.split(torch.where(target_labels[(2 * i):(2 * (i + 1))].sum(0))[0], int(60000 / num_clients))\n",
    "traindata_split = [torch.utils.data.Subset(traindata, tl) for tl in target_labels_split]\n",
    "train_loader = [torch.utils.data.DataLoader(x, batch_size=batch_size, shuffle=True) for x in traindata_split]\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('./data', train=False, transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))])\n",
    "        ), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Instantiate models and optimizers\n",
    "\n",
    "global_model = Net().cuda()\n",
    "client_models = [Net().cuda() for _ in range(num_selected)]\n",
    "for model in client_models:\n",
    "    model.load_state_dict(global_model.state_dict())\n",
    "\n",
    "opt = [optim.SGD(model.parameters(), lr=0.1) for model in client_models]\n",
    "\n",
    "# Runnining FL\n",
    "\n",
    "for r in range(num_rounds):\n",
    "    # select random clients\n",
    "    client_idx = np.random.permutation(num_clients)[:num_selected]\n",
    "\n",
    "    # client update\n",
    "    loss = 0\n",
    "    for i in range(num_selected):\n",
    "        loss += client_update(client_models[i], opt[i], train_loader[client_idx[i]], epoch=epochs)\n",
    "    \n",
    "    # serer aggregate\n",
    "    server_aggregate(global_model, client_models)\n",
    "    test_loss, acc = test(global_model, test_loader)\n",
    "    \n",
    "    print('%d-th round' % r)\n",
    "    print('average train loss %0.3g | test loss %0.3g | test acc: %0.3f' % (loss / num_selected, test_loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 ('pytorch-DL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "7d758705e618b7682fd9abc9f470e0e438b871c30fff4a0c530627e8e4c87c28"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
